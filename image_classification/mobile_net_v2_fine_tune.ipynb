{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune MobileNetV2\n",
    "This notebook will load in some training data that has been downloaded from [Imagenet](http://image-net.org/explore) and use it to train the model to predict if an image is from one of these five categories:\n",
    "- chair\n",
    "- couch\n",
    "- table\n",
    "- lamp\n",
    "- bed\n",
    "\n",
    "Note: A later version of this notebook will use [ImageDataGenerator](https://keras.io/preprocessing/image/) ([addition info](https://machinelearningmastery.com/image-augmentation-deep-learning-keras/)) to augment the training data. This should help to [further reduce the validation accuracy](https://www.learnopencv.com/keras-tutorial-fine-tuning-using-pre-trained-models/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dave/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras import layers, models, optimizers\n",
    "from keras_applications import mobilenet_v2 \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.imagenet.get_images import get_imagenet_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 224 is the default image size for MobileNetV2 (and many other pre-trained models on Keras)\n",
    "image_size = 224\n",
    "mobilenet_conv = mobilenet_v2.MobileNetV2(weights='imagenet',\n",
    "                                          include_top=False,\n",
    "                                          input_shape=(image_size, image_size, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify types of images to download\n",
    "download_info = {\n",
    "    # Imagenet_ID: type_of_image \n",
    "    'n03325403': 'chair',\n",
    "    'n03015149': 'couch',\n",
    "    'n04379243': 'table',\n",
    "    'n03636649': 'lamp',\n",
    "    'n03225988': 'bed'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TypeError: cannot identify image file '../downloaded_images/fine_tuning/lamp/7fe710dcb617bc68537cf5906469add2441eac38.jpg'\n",
      "TypeError: cannot identify image file '../downloaded_images/fine_tuning/lamp/a7c4638420d81cb0aaac25c401545e09c9d1c245.jpg'\n",
      "Mapping:\n",
      "{'bed': 0, 'chair': 1, 'couch': 2, 'lamp': 3, 'table': 4}\n"
     ]
    }
   ],
   "source": [
    "# Download, process, and load the images\n",
    "processed_images, images_class_softmax = get_imagenet_data(\n",
    "    download=False,\n",
    "    download_info=download_info,\n",
    "    directory='../downloaded_images/fine_tuning',\n",
    "    images_per_type=500,\n",
    "    image_size=image_size,\n",
    "    process=True,\n",
    "    model=mobilenet_v2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our fine-tuned model\n",
    "Since we did not include the 'top' (the layer that predicts the type/class of image) of the model when loading it, we need to add this layer to the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Model) (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 6405      \n",
      "=================================================================\n",
      "Total params: 2,264,389\n",
      "Trainable params: 2,230,277\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "N_CATEGORIES = len(download_info.values())\n",
    "\n",
    "# Create model (currently empty)\n",
    "model = models.Sequential()\n",
    "# Add MobileNetV2\n",
    "model.add(mobilenet_conv)\n",
    "# Add global pooling layer, which was also left out of the 'top'\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "# Add dropout to reduce overfitting\n",
    "model.add(layers.Dropout(0.5))\n",
    "# Add layer to predict class\n",
    "model.add(layers.Dense(N_CATEGORIES, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1857, 224, 224, 3), 1857)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(processed_images,\n",
    "                                                    images_class_softmax,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=images_class_softmax,\n",
    "                                                    random_state=2)\n",
    "\n",
    "x_train.shape, len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model\n",
    "Define the [key features](https://stackoverflow.com/questions/47995324/does-model-compile-initialize-all-the-weights-and-biases-in-keras-tensorflow) of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "In the interest of saving time and not needing greater results at the moment, the model is only being trained for three epochs and with 1000 images. Both of these numbers are very small and I expect the validation accurary to greatly improve when we increase these values. However, using a GPU, rather than my laptop, would be much more practical for this next step.\n",
    "\n",
    "Given the simplicity of this work, I'm rather pleased that the validation accuracy is almost 90%. Another thing that I would change for a more formal training of the model is removing sub-par images from the dataset. Some images include humans, pairs of objects, or are poorly focused. This cleaning of the data will indoubtably further improve the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 465 samples\n",
      "Epoch 1/3\n",
      "1000/1000 [==============================] - 636s 636ms/step - loss: 1.1108 - acc: 0.5980 - val_loss: 0.5036 - val_acc: 0.8624\n",
      "Epoch 2/3\n",
      "1000/1000 [==============================] - 667s 667ms/step - loss: 0.3637 - acc: 0.8900 - val_loss: 0.3781 - val_acc: 0.8925\n",
      "Epoch 3/3\n",
      "1000/1000 [==============================] - 675s 675ms/step - loss: 0.1760 - acc: 0.9460 - val_loss: 0.3303 - val_acc: 0.8925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11d9a45c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train[:1000],\n",
    "          y_train[:1000],\n",
    "          batch_size=32,\n",
    "          epochs=3,\n",
    "          validation_data=[x_test, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018_07_29_mobilenet_v2_8925'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_today = datetime.today().strftime('%Y_%m_%d')\n",
    "model_name = 'mobilenet_v2'\n",
    "accuracy = str(round(model.history.history['val_acc'][-1], 4)).split('.')[1]\n",
    "\n",
    "save_string = date_today + '_' + model_name + '_' + accuracy\n",
    "save_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('saved_models/{}.h5'.format(save_string))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
